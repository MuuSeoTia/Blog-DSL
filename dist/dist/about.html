<!DOCTYPE HTML><html><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1"><title>About - Mouad Tiahi</title><link rel="stylesheet" type="text/css" href="css/style.css"><link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&amp;family=Source+Serif+4:wght@400;600;700&amp;display=swap"></head><body><div class="site"><a class="skip-link" href="#main-content">Skip to content</a><nav class="nav" role="navigation" aria-label="Main navigation"><a href="index.html" class="nav-name"><span class="full-name">Mouad Tiahi</span><span class="short-name">Mouad</span></a><div class="nav-links"><a href="index.html">~/</a><a href="about.html">About</a><a href="projects.html">Projects</a><a href="experience.html">Experience</a></div></nav><main class="content" id="main-content" role="main"><h1>About</h1><img class="section-img" src="images/beanpot.jpg" alt="Mouad Tiahi"><p>I&#39;m a Computer Science and Physics student at Northeastern University, graduating in 2027. I&#39;ve interned at Amazon building cloud infrastructure and at Dell Technologies working on private cloud engineering. Currently, I work as a Machine Learning and High Performance Computing researcher at the NUCAR Lab under Professor David Kaeli.</p><p>Outside of research, I serve as Chief Operating Officer of IDEA, Northeastern&#39;s venture accelerator, where I lead a team of 30+ students and manage software infrastructure supporting 2,800+ student ventures.</p><p>My research focuses on high-performance computing optimization — particularly sparse matrix operations on GPU architectures using CUDA and compiler-level instrumentation with NvBit. I&#39;ve published work at MIT IEEE on distributed RAG retrieval systems.</p><h2>Interests</h2><p>Machine learning systems, GPU/TPU kernel engineering, compiler design, quantum computing, and the intersection of physics and computation. I also compete in hackathons — five wins so far.</p><h2>Currently Learning</h2><ul><li>Sparsity in NVIDIA architectures for accelerating inference</li><li>MXFP4 micro-scaling formats and low-precision arithmetic for NVIDIA Blackwell architectures</li><li>JAX, Pallas, and TPU kernel optimization</li></ul></main><footer class="footer" role="contentinfo"><p>Built with <a href="https://github.com/MuuSeoTia/Blog-DSL" target="_blank">my Haskell DSL</a></p></footer></div></body></html>